data:
  preparsed_data_path: "./data/train_data/preparsed_train_data.json"
  train_data_path: "./data/train_data/train_data.json"
  test_data_path: "./data/test_data/test_data.json"

model:
  use_gpu: false
  pretrained:
    model_path: "cardiffnlp/twitter-xlm-roberta-base-sentiment"
    tokenizer: "cardiffnlp/twitter-xlm-roberta-base-sentiment"
  tuned:
    model_path: "./sentiment_model"
    tokenizer: "./sentiment_model"
  ru_model:
    model_path: "r1char9/rubert-base-cased-russian-sentiment"
    tokenizer: "r1char9/rubert-base-cased-russian-sentiment"
  use_tuned: false
  use_ru: true

training:
  eval_strategy: "epoch" # Валидация модели после завершения эпохи оубчения
  save_strategy: "epoch" # Сохранение модели после каждой эпохи
  learning_rate: !!float 2e-5 # Скорость обучения (корректирование весов на шаге обучения)
  per_device_train_batch_size: 16 # Количество примеров, обрабатываемых на одном устройстве за шаг
  per_device_eval_batch_size: 16 # Количество примеров для оценки на валидационном наборе
  num_train_epochs: 3 # Количество эпох обучения (3 круга обучения на одном наборе)
  weight_decay: 0.01 # Уменьшение значения весов после каждого шага обучения
  save_total_limit: 2 # Контрольные точки для непредвиденных случаев сбоя/отладки и пр.
  logging_dir: "./logs"